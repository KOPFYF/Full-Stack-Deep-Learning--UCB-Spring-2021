{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab3-RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsjJ1Q-_fp90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a993ddb7-200c-4ffd-da98-f9a1f1395792"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Aug 15 20:28:13 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdvS4qlQgBYO",
        "outputId": "d6fc4779-0447-4751-bba3-6365ec2dda87"
      },
      "source": [
        "# FSDL Spring 2021 Setup\n",
        "!git clone https://github.com/full-stack-deep-learning/fsdl-text-recognizer-2021-labs\n",
        "%cd fsdl-text-recognizer-2021-labs\n",
        "!pip3 install boltons wandb pytorch_lightning==1.1.4 pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 torchtext==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "%env PYTHONPATH=.:$PYTHONPATH"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fsdl-text-recognizer-2021-labs'...\n",
            "remote: Enumerating objects: 798, done.\u001b[K\n",
            "remote: Counting objects: 100% (232/232), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 798 (delta 158), reused 144 (delta 140), pack-reused 566\u001b[K\n",
            "Receiving objects: 100% (798/798), 18.89 MiB | 26.57 MiB/s, done.\n",
            "Resolving deltas: 100% (394/394), done.\n",
            "/content/fsdl-text-recognizer-2021-labs\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting boltons\n",
            "  Downloading boltons-21.0.0-py2.py3-none-any.whl (193 kB)\n",
            "\u001b[K     |████████████████████████████████| 193 kB 8.0 MB/s \n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.12.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 61.9 MB/s \n",
            "\u001b[?25hCollecting pytorch_lightning==1.1.4\n",
            "  Downloading pytorch_lightning-1.1.4-py3-none-any.whl (684 kB)\n",
            "\u001b[K     |████████████████████████████████| 684 kB 63.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Requirement already satisfied: install in /usr/local/lib/python3.7/dist-packages (1.3.4)\n",
            "Collecting torch==1.7.1+cu110\n",
            "  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8 MB)\n",
            "\u001b[K     |███████████████████████         | 834.1 MB 1.2 MB/s eta 0:04:21tcmalloc: large alloc 1147494400 bytes == 0x55eabe0cc000 @  0x7f0864572615 0x55eabab0802c 0x55eababe817a 0x55eabab0ae4d 0x55eababfcc0d 0x55eabab7f0d8 0x55eabab79c35 0x55eabab0c73a 0x55eabab7ef40 0x55eabab79c35 0x55eabab0c73a 0x55eabab7b93b 0x55eababfda56 0x55eabab7afb3 0x55eababfda56 0x55eabab7afb3 0x55eababfda56 0x55eabab7afb3 0x55eabab0cb99 0x55eabab4fe79 0x55eabab0b7b2 0x55eabab7ee65 0x55eabab79c35 0x55eabab0c73a 0x55eabab7b93b 0x55eabab79c35 0x55eabab0c73a 0x55eabab7ab0e 0x55eabab0c65a 0x55eabab7ad67 0x55eabab79c35\n",
            "\u001b[K     |█████████████████████████████▏  | 1055.7 MB 1.2 MB/s eta 0:01:24tcmalloc: large alloc 1434370048 bytes == 0x55eb02722000 @  0x7f0864572615 0x55eabab0802c 0x55eababe817a 0x55eabab0ae4d 0x55eababfcc0d 0x55eabab7f0d8 0x55eabab79c35 0x55eabab0c73a 0x55eabab7ef40 0x55eabab79c35 0x55eabab0c73a 0x55eabab7b93b 0x55eababfda56 0x55eabab7afb3 0x55eababfda56 0x55eabab7afb3 0x55eababfda56 0x55eabab7afb3 0x55eabab0cb99 0x55eabab4fe79 0x55eabab0b7b2 0x55eabab7ee65 0x55eabab79c35 0x55eabab0c73a 0x55eabab7b93b 0x55eabab79c35 0x55eabab0c73a 0x55eabab7ab0e 0x55eabab0c65a 0x55eabab7ad67 0x55eabab79c35\n",
            "\u001b[K     |████████████████████████████████| 1156.7 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 1445945344 bytes == 0x55eb9ce38000 @  0x7f0864572615 0x55eabab0802c 0x55eababe817a 0x55eabab0ae4d 0x55eababfcc0d 0x55eabab7f0d8 0x55eabab79c35 0x55eabab0c73a 0x55eabab7ad67 0x55eabab79c35 0x55eabab0c73a 0x55eabab7ad67 0x55eabab79c35 0x55eabab0c73a 0x55eabab7ad67 0x55eabab79c35 0x55eabab0c73a 0x55eabab7ad67 0x55eabab79c35 0x55eabab0c73a 0x55eabab7ad67 0x55eabab0c65a 0x55eabab7ad67 0x55eabab79c35 0x55eabab0c73a 0x55eabab7b93b 0x55eabab79c35 0x55eabab0c73a 0x55eabab7b93b 0x55eabab79c35 0x55eabab0cdd1\n",
            "\u001b[K     |████████████████████████████████| 1156.8 MB 13 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2+cu110\n",
            "  Downloading https://download.pytorch.org/whl/cu110/torchvision-0.8.2%2Bcu110-cp37-cp37m-linux_x86_64.whl (12.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.9 MB 163 kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.7.2\n",
            "  Downloading torchaudio-0.7.2-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 20.3 MB/s \n",
            "\u001b[?25hCollecting torchtext==0.8.1\n",
            "  Downloading torchtext-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 29.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (4.62.0)\n",
            "Collecting fsspec[http]>=0.8.1\n",
            "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 74.1 MB/s \n",
            "\u001b[?25hCollecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 48.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (1.19.5)\n",
            "Collecting PyYAML>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 73.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu110) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (2.23.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 60.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.4.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.37.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (57.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.3.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.8.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.34.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.34.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (4.6.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.1.1)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.3.1-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 79.5 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 65.5 MB/s \n",
            "\u001b[?25hCollecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 8.4 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 70.6 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 72.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (21.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.5.0)\n",
            "Building wheels for collected packages: future, subprocess32, pathtools\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=19f2ff51c725f83424d4ff37bc2d2d95247ea3f5a63bf184374f4a9920f11cfe\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=e8d0b27340dfcb520f2a04e9cee448df15c15cc0e43c0e5f1800f200cb0f5778\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=e4b9bf5ad38520ba0d67c00cd4630628d38acf7a51ac0c4f5c1594bd3470792d\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built future subprocess32 pathtools\n",
            "Installing collected packages: multidict, yarl, smmap, async-timeout, gitdb, fsspec, aiohttp, torch, subprocess32, shortuuid, sentry-sdk, PyYAML, pathtools, GitPython, future, docker-pycreds, configparser, wandb, torchvision, torchtext, torchaudio, pytorch-lightning, boltons\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu102\n",
            "    Uninstalling torchvision-0.10.0+cu102:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu102\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.10.0\n",
            "    Uninstalling torchtext-0.10.0:\n",
            "      Successfully uninstalled torchtext-0.10.0\n",
            "Successfully installed GitPython-3.1.18 PyYAML-5.4.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 boltons-21.0.0 configparser-5.0.2 docker-pycreds-0.4.0 fsspec-2021.7.0 future-0.18.2 gitdb-4.0.7 multidict-5.1.0 pathtools-0.1.2 pytorch-lightning-1.1.4 sentry-sdk-1.3.1 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 torch-1.7.1+cu110 torchaudio-0.7.2 torchtext-0.8.1 torchvision-0.8.2+cu110 wandb-0.12.0 yarl-1.6.3\n",
            "env: PYTHONPATH=.:$PYTHONPATH\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-tXmRWP1gDH-",
        "outputId": "d8e0cf2c-09c7-4bf6-b7d3-470df79afb5e"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/fsdl-text-recognizer-2021-labs'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r26fKFo3giG1",
        "outputId": "dd77452e-5bb9-4607-f08e-f8c158896808"
      },
      "source": [
        "%cd lab3/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fsdl-text-recognizer-2021-labs/lab3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U49-uVL9gmOU",
        "outputId": "2badb5af-49bf-4007-e779-502d948ad466"
      },
      "source": [
        "# 28-28, char by char, with 0 overlap\n",
        "# cross entropy loss, \n",
        "# https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html#torch.nn.functional.cross_entropy\n",
        "!python training/run_experiment.py --max_epochs=10 --gpus=1 --num_workers=4 --data_class=EMNISTLines --min_overlap=0 --max_overlap=0 --model_class=LineCNNSimple --window_width=28 --window_stride=28"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "EMNISTLinesDataset generating data for train...\n",
            "[nltk_data] Downloading package brown to /content/fsdl-text-\n",
            "[nltk_data]     recognizer-2021-labs/data/downloaded/nltk...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "Downloading raw dataset from https://s3-us-west-2.amazonaws.com/fsdl-public-assets/matlab.zip to /content/fsdl-text-recognizer-2021-labs/data/downloaded/emnist/matlab.zip...\n",
            "709MB [00:08, 87.5MB/s]              \n",
            "Computing SHA-256...\n",
            "Unzipping EMNIST...\n",
            "Loading training data from .mat file\n",
            "Balancing classes to reduce amount of data\n",
            "Saving to HDF5 in a compressed format...\n",
            "Saving essential dataset parameters to text_recognizer/datasets...\n",
            "Cleaning up...\n",
            "EMNISTLinesDataset generating data for val...\n",
            "EMNISTLinesDataset generating data for test...\n",
            "EMNISTLinesDataset loading data from HDF5...\n",
            "2021-08-15 20:35:24.696181: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "   | Name                 | Type          | Params\n",
            "--------------------------------------------------------\n",
            "0  | model                | LineCNNSimple | 1.7 M \n",
            "1  | model.cnn            | CNN           | 1.7 M \n",
            "2  | model.cnn.conv1      | ConvBlock     | 640   \n",
            "3  | model.cnn.conv1.conv | Conv2d        | 640   \n",
            "4  | model.cnn.conv1.relu | ReLU          | 0     \n",
            "5  | model.cnn.conv2      | ConvBlock     | 36.9 K\n",
            "6  | model.cnn.conv2.conv | Conv2d        | 36.9 K\n",
            "7  | model.cnn.conv2.relu | ReLU          | 0     \n",
            "8  | model.cnn.dropout    | Dropout       | 0     \n",
            "9  | model.cnn.max_pool   | MaxPool2d     | 0     \n",
            "10 | model.cnn.fc1        | Linear        | 1.6 M \n",
            "11 | model.cnn.fc2        | Linear        | 10.7 K\n",
            "12 | train_acc            | Accuracy      | 0     \n",
            "13 | val_acc              | Accuracy      | 0     \n",
            "14 | test_acc             | Accuracy      | 0     \n",
            "--------------------------------------------------------\n",
            "1.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.7 M     Total params\n",
            "Epoch 0:  83% 79/95 [00:23<00:04,  3.39it/s, loss=0.531, v_num=0, val_loss=4.45, val_acc=0.0101]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  85% 81/95 [00:23<00:04,  3.41it/s, loss=0.531, v_num=0, val_loss=4.45, val_acc=0.0101]\n",
            "Epoch 0:  87% 83/95 [00:23<00:03,  3.47it/s, loss=0.531, v_num=0, val_loss=4.45, val_acc=0.0101]\n",
            "Epoch 0:  89% 85/95 [00:24<00:02,  3.53it/s, loss=0.531, v_num=0, val_loss=4.45, val_acc=0.0101]\n",
            "Epoch 0:  92% 87/95 [00:24<00:02,  3.58it/s, loss=0.531, v_num=0, val_loss=4.45, val_acc=0.0101]\n",
            "Epoch 0:  94% 89/95 [00:24<00:01,  3.64it/s, loss=0.531, v_num=0, val_loss=4.45, val_acc=0.0101]\n",
            "Epoch 0:  96% 91/95 [00:24<00:01,  3.69it/s, loss=0.531, v_num=0, val_loss=4.45, val_acc=0.0101]\n",
            "Epoch 0:  98% 93/95 [00:24<00:00,  3.75it/s, loss=0.531, v_num=0, val_loss=4.45, val_acc=0.0101]\n",
            "Epoch 0: 100% 95/95 [00:25<00:00,  3.75it/s, loss=0.531, v_num=0, val_loss=0.505, val_acc=0.725]\n",
            "Epoch 1:  84% 80/95 [00:23<00:04,  3.41it/s, loss=0.408, v_num=0, val_loss=0.505, val_acc=0.725]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1:  86% 82/95 [00:24<00:03,  3.41it/s, loss=0.408, v_num=0, val_loss=0.505, val_acc=0.725]\n",
            "Epoch 1:  88% 84/95 [00:24<00:03,  3.47it/s, loss=0.408, v_num=0, val_loss=0.505, val_acc=0.725]\n",
            "Epoch 1:  91% 86/95 [00:24<00:02,  3.53it/s, loss=0.408, v_num=0, val_loss=0.505, val_acc=0.725]\n",
            "Epoch 1:  93% 88/95 [00:24<00:01,  3.58it/s, loss=0.408, v_num=0, val_loss=0.505, val_acc=0.725]\n",
            "Epoch 1:  95% 90/95 [00:24<00:01,  3.63it/s, loss=0.408, v_num=0, val_loss=0.505, val_acc=0.725]\n",
            "Epoch 1:  97% 92/95 [00:24<00:00,  3.69it/s, loss=0.408, v_num=0, val_loss=0.505, val_acc=0.725]\n",
            "Epoch 1:  99% 94/95 [00:25<00:00,  3.74it/s, loss=0.408, v_num=0, val_loss=0.505, val_acc=0.725]\n",
            "Epoch 1: 100% 95/95 [00:25<00:00,  3.72it/s, loss=0.408, v_num=0, val_loss=0.392, val_acc=0.761]\n",
            "Epoch 2:  84% 80/95 [00:23<00:04,  3.38it/s, loss=0.356, v_num=0, val_loss=0.392, val_acc=0.761]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 2:  86% 82/95 [00:24<00:03,  3.39it/s, loss=0.356, v_num=0, val_loss=0.392, val_acc=0.761]\n",
            "Epoch 2:  88% 84/95 [00:24<00:03,  3.45it/s, loss=0.356, v_num=0, val_loss=0.392, val_acc=0.761]\n",
            "Epoch 2:  91% 86/95 [00:24<00:02,  3.50it/s, loss=0.356, v_num=0, val_loss=0.392, val_acc=0.761]\n",
            "Epoch 2:  93% 88/95 [00:24<00:01,  3.56it/s, loss=0.356, v_num=0, val_loss=0.392, val_acc=0.761]\n",
            "Epoch 2:  95% 90/95 [00:24<00:01,  3.61it/s, loss=0.356, v_num=0, val_loss=0.392, val_acc=0.761]\n",
            "Epoch 2:  97% 92/95 [00:25<00:00,  3.66it/s, loss=0.356, v_num=0, val_loss=0.392, val_acc=0.761]\n",
            "Epoch 2:  99% 94/95 [00:25<00:00,  3.72it/s, loss=0.356, v_num=0, val_loss=0.392, val_acc=0.761]\n",
            "Epoch 2: 100% 95/95 [00:25<00:00,  3.70it/s, loss=0.356, v_num=0, val_loss=0.349, val_acc=0.795]\n",
            "Epoch 3:  84% 80/95 [00:23<00:04,  3.34it/s, loss=0.336, v_num=0, val_loss=0.349, val_acc=0.795]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 3:  86% 82/95 [00:24<00:03,  3.35it/s, loss=0.336, v_num=0, val_loss=0.349, val_acc=0.795]\n",
            "Epoch 3:  88% 84/95 [00:24<00:03,  3.41it/s, loss=0.336, v_num=0, val_loss=0.349, val_acc=0.795]\n",
            "Epoch 3:  91% 86/95 [00:24<00:02,  3.46it/s, loss=0.336, v_num=0, val_loss=0.349, val_acc=0.795]\n",
            "Epoch 3:  93% 88/95 [00:25<00:01,  3.52it/s, loss=0.336, v_num=0, val_loss=0.349, val_acc=0.795]\n",
            "Epoch 3:  95% 90/95 [00:25<00:01,  3.57it/s, loss=0.336, v_num=0, val_loss=0.349, val_acc=0.795]\n",
            "Epoch 3:  97% 92/95 [00:25<00:00,  3.62it/s, loss=0.336, v_num=0, val_loss=0.349, val_acc=0.795]\n",
            "Epoch 3:  99% 94/95 [00:25<00:00,  3.68it/s, loss=0.336, v_num=0, val_loss=0.349, val_acc=0.795]\n",
            "Epoch 3: 100% 95/95 [00:25<00:00,  3.65it/s, loss=0.336, v_num=0, val_loss=0.331, val_acc=0.829]\n",
            "Epoch 4:  84% 80/95 [00:23<00:04,  3.33it/s, loss=0.324, v_num=0, val_loss=0.331, val_acc=0.829]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:05,  2.58it/s]\u001b[A\n",
            "Epoch 4:  86% 82/95 [00:24<00:03,  3.35it/s, loss=0.324, v_num=0, val_loss=0.331, val_acc=0.829]\n",
            "Epoch 4:  88% 84/95 [00:24<00:03,  3.40it/s, loss=0.324, v_num=0, val_loss=0.331, val_acc=0.829]\n",
            "Epoch 4:  91% 86/95 [00:24<00:02,  3.46it/s, loss=0.324, v_num=0, val_loss=0.331, val_acc=0.829]\n",
            "Epoch 4:  93% 88/95 [00:25<00:01,  3.51it/s, loss=0.324, v_num=0, val_loss=0.331, val_acc=0.829]\n",
            "Epoch 4:  95% 90/95 [00:25<00:01,  3.57it/s, loss=0.324, v_num=0, val_loss=0.331, val_acc=0.829]\n",
            "Epoch 4:  97% 92/95 [00:25<00:00,  3.62it/s, loss=0.324, v_num=0, val_loss=0.331, val_acc=0.829]\n",
            "Epoch 4:  99% 94/95 [00:25<00:00,  3.67it/s, loss=0.324, v_num=0, val_loss=0.331, val_acc=0.829]\n",
            "Epoch 4: 100% 95/95 [00:25<00:00,  3.66it/s, loss=0.324, v_num=0, val_loss=0.32, val_acc=0.827] \n",
            "Epoch 5:  84% 80/95 [00:23<00:04,  3.36it/s, loss=0.313, v_num=0, val_loss=0.32, val_acc=0.827]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 5:  86% 82/95 [00:24<00:03,  3.37it/s, loss=0.313, v_num=0, val_loss=0.32, val_acc=0.827]\n",
            "Epoch 5:  88% 84/95 [00:24<00:03,  3.43it/s, loss=0.313, v_num=0, val_loss=0.32, val_acc=0.827]\n",
            "Epoch 5:  91% 86/95 [00:24<00:02,  3.48it/s, loss=0.313, v_num=0, val_loss=0.32, val_acc=0.827]\n",
            "Epoch 5:  93% 88/95 [00:24<00:01,  3.54it/s, loss=0.313, v_num=0, val_loss=0.32, val_acc=0.827]\n",
            "Epoch 5:  95% 90/95 [00:25<00:01,  3.59it/s, loss=0.313, v_num=0, val_loss=0.32, val_acc=0.827]\n",
            "Epoch 5:  97% 92/95 [00:25<00:00,  3.64it/s, loss=0.313, v_num=0, val_loss=0.32, val_acc=0.827]\n",
            "Epoch 5:  99% 94/95 [00:25<00:00,  3.69it/s, loss=0.313, v_num=0, val_loss=0.32, val_acc=0.827]\n",
            "Epoch 5: 100% 95/95 [00:25<00:00,  3.67it/s, loss=0.313, v_num=0, val_loss=0.318, val_acc=0.826]\n",
            "Epoch 6:  84% 80/95 [00:23<00:04,  3.35it/s, loss=0.305, v_num=0, val_loss=0.318, val_acc=0.826]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:06,  2.45it/s]\u001b[A\n",
            "Epoch 6:  86% 82/95 [00:24<00:03,  3.36it/s, loss=0.305, v_num=0, val_loss=0.318, val_acc=0.826]\n",
            "Epoch 6:  88% 84/95 [00:24<00:03,  3.42it/s, loss=0.305, v_num=0, val_loss=0.318, val_acc=0.826]\n",
            "Epoch 6:  91% 86/95 [00:24<00:02,  3.48it/s, loss=0.305, v_num=0, val_loss=0.318, val_acc=0.826]\n",
            "Epoch 6:  93% 88/95 [00:24<00:01,  3.53it/s, loss=0.305, v_num=0, val_loss=0.318, val_acc=0.826]\n",
            "Epoch 6:  95% 90/95 [00:25<00:01,  3.58it/s, loss=0.305, v_num=0, val_loss=0.318, val_acc=0.826]\n",
            "Epoch 6:  97% 92/95 [00:25<00:00,  3.64it/s, loss=0.305, v_num=0, val_loss=0.318, val_acc=0.826]\n",
            "Epoch 6:  99% 94/95 [00:25<00:00,  3.69it/s, loss=0.305, v_num=0, val_loss=0.318, val_acc=0.826]\n",
            "Epoch 6: 100% 95/95 [00:25<00:00,  3.67it/s, loss=0.305, v_num=0, val_loss=0.31, val_acc=0.829] \n",
            "Epoch 7:  84% 80/95 [00:23<00:04,  3.34it/s, loss=0.301, v_num=0, val_loss=0.31, val_acc=0.829]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 7:  86% 82/95 [00:24<00:03,  3.35it/s, loss=0.301, v_num=0, val_loss=0.31, val_acc=0.829]\n",
            "Epoch 7:  88% 84/95 [00:24<00:03,  3.40it/s, loss=0.301, v_num=0, val_loss=0.31, val_acc=0.829]\n",
            "Epoch 7:  91% 86/95 [00:24<00:02,  3.46it/s, loss=0.301, v_num=0, val_loss=0.31, val_acc=0.829]\n",
            "Epoch 7:  93% 88/95 [00:25<00:01,  3.51it/s, loss=0.301, v_num=0, val_loss=0.31, val_acc=0.829]\n",
            "Epoch 7:  95% 90/95 [00:25<00:01,  3.57it/s, loss=0.301, v_num=0, val_loss=0.31, val_acc=0.829]\n",
            "Epoch 7:  97% 92/95 [00:25<00:00,  3.62it/s, loss=0.301, v_num=0, val_loss=0.31, val_acc=0.829]\n",
            "Epoch 7:  99% 94/95 [00:25<00:00,  3.67it/s, loss=0.301, v_num=0, val_loss=0.31, val_acc=0.829]\n",
            "Epoch 7: 100% 95/95 [00:26<00:00,  3.65it/s, loss=0.301, v_num=0, val_loss=0.305, val_acc=0.827]\n",
            "Epoch 8:  84% 80/95 [00:23<00:04,  3.35it/s, loss=0.293, v_num=0, val_loss=0.305, val_acc=0.827]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 8:  86% 82/95 [00:24<00:03,  3.36it/s, loss=0.293, v_num=0, val_loss=0.305, val_acc=0.827]\n",
            "Epoch 8:  88% 84/95 [00:24<00:03,  3.41it/s, loss=0.293, v_num=0, val_loss=0.305, val_acc=0.827]\n",
            "Epoch 8:  91% 86/95 [00:24<00:02,  3.47it/s, loss=0.293, v_num=0, val_loss=0.305, val_acc=0.827]\n",
            "Epoch 8:  93% 88/95 [00:24<00:01,  3.52it/s, loss=0.293, v_num=0, val_loss=0.305, val_acc=0.827]\n",
            "Epoch 8:  95% 90/95 [00:25<00:01,  3.58it/s, loss=0.293, v_num=0, val_loss=0.305, val_acc=0.827]\n",
            "Epoch 8:  97% 92/95 [00:25<00:00,  3.63it/s, loss=0.293, v_num=0, val_loss=0.305, val_acc=0.827]\n",
            "Epoch 8:  99% 94/95 [00:25<00:00,  3.68it/s, loss=0.293, v_num=0, val_loss=0.305, val_acc=0.827]\n",
            "Epoch 8: 100% 95/95 [00:25<00:00,  3.66it/s, loss=0.293, v_num=0, val_loss=0.303, val_acc=0.825]\n",
            "Epoch 9:  84% 80/95 [00:23<00:04,  3.36it/s, loss=0.289, v_num=0, val_loss=0.303, val_acc=0.825]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 9:  86% 82/95 [00:24<00:03,  3.36it/s, loss=0.289, v_num=0, val_loss=0.303, val_acc=0.825]\n",
            "Epoch 9:  88% 84/95 [00:24<00:03,  3.42it/s, loss=0.289, v_num=0, val_loss=0.303, val_acc=0.825]\n",
            "Epoch 9:  91% 86/95 [00:24<00:02,  3.47it/s, loss=0.289, v_num=0, val_loss=0.303, val_acc=0.825]\n",
            "Epoch 9:  93% 88/95 [00:24<00:01,  3.53it/s, loss=0.289, v_num=0, val_loss=0.303, val_acc=0.825]\n",
            "Epoch 9:  95% 90/95 [00:25<00:01,  3.58it/s, loss=0.289, v_num=0, val_loss=0.303, val_acc=0.825]\n",
            "Epoch 9:  97% 92/95 [00:25<00:00,  3.63it/s, loss=0.289, v_num=0, val_loss=0.303, val_acc=0.825]\n",
            "Epoch 9:  99% 94/95 [00:25<00:00,  3.69it/s, loss=0.289, v_num=0, val_loss=0.303, val_acc=0.825]\n",
            "Epoch 9: 100% 95/95 [00:25<00:00,  3.68it/s, loss=0.289, v_num=0, val_loss=0.305, val_acc=0.825]\n",
            "Epoch 9: 100% 95/95 [00:25<00:00,  3.68it/s, loss=0.289, v_num=0, val_loss=0.305, val_acc=0.825]\n",
            "EMNISTLinesDataset loading data from HDF5...\n",
            "Testing: 100% 16/16 [00:01<00:00,  8.14it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.8222, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA9Kncp6hZWP",
        "outputId": "bfcd375a-5d21-4ff5-c3d2-a5a9c30b428b"
      },
      "source": [
        "# now test overlap, 28-20\n",
        "# so now the overlap would be (28-20) / 20 = 0.25\n",
        "# --limit_output_length\n",
        "\n",
        "!python training/run_experiment.py --max_epochs=10 --gpus=1 --num_workers=4 --data_class=EMNISTLines --min_overlap=0.25 --max_overlap=0.25 --model_class=LineCNNSimple --window_width=28 --window_stride=20 --limit_output_length"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "EMNISTLinesDataset generating data for train...\n",
            "EMNISTLinesDataset generating data for val...\n",
            "EMNISTLinesDataset generating data for test...\n",
            "EMNISTLinesDataset loading data from HDF5...\n",
            "2021-08-15 20:42:14.979882: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "   | Name                 | Type          | Params\n",
            "--------------------------------------------------------\n",
            "0  | model                | LineCNNSimple | 1.7 M \n",
            "1  | model.cnn            | CNN           | 1.7 M \n",
            "2  | model.cnn.conv1      | ConvBlock     | 640   \n",
            "3  | model.cnn.conv1.conv | Conv2d        | 640   \n",
            "4  | model.cnn.conv1.relu | ReLU          | 0     \n",
            "5  | model.cnn.conv2      | ConvBlock     | 36.9 K\n",
            "6  | model.cnn.conv2.conv | Conv2d        | 36.9 K\n",
            "7  | model.cnn.conv2.relu | ReLU          | 0     \n",
            "8  | model.cnn.dropout    | Dropout       | 0     \n",
            "9  | model.cnn.max_pool   | MaxPool2d     | 0     \n",
            "10 | model.cnn.fc1        | Linear        | 1.6 M \n",
            "11 | model.cnn.fc2        | Linear        | 10.7 K\n",
            "12 | train_acc            | Accuracy      | 0     \n",
            "13 | val_acc              | Accuracy      | 0     \n",
            "14 | test_acc             | Accuracy      | 0     \n",
            "--------------------------------------------------------\n",
            "1.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.7 M     Total params\n",
            "Epoch 0:  83% 79/95 [00:31<00:06,  2.49it/s, loss=1.01, v_num=1, val_loss=4.46, val_acc=0.00781]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  85% 81/95 [00:32<00:05,  2.52it/s, loss=1.01, v_num=1, val_loss=4.46, val_acc=0.00781]\n",
            "Validating:  12% 2/16 [00:00<00:03,  4.09it/s]\u001b[A\n",
            "Epoch 0:  87% 83/95 [00:32<00:04,  2.56it/s, loss=1.01, v_num=1, val_loss=4.46, val_acc=0.00781]\n",
            "Validating:  25% 4/16 [00:00<00:01,  6.07it/s]\u001b[A\n",
            "Epoch 0:  89% 85/95 [00:32<00:03,  2.61it/s, loss=1.01, v_num=1, val_loss=4.46, val_acc=0.00781]\n",
            "Validating:  38% 6/16 [00:01<00:01,  7.05it/s]\u001b[A\n",
            "Epoch 0:  92% 87/95 [00:32<00:03,  2.65it/s, loss=1.01, v_num=1, val_loss=4.46, val_acc=0.00781]\n",
            "Validating:  50% 8/16 [00:01<00:01,  7.47it/s]\u001b[A\n",
            "Epoch 0:  94% 89/95 [00:33<00:02,  2.69it/s, loss=1.01, v_num=1, val_loss=4.46, val_acc=0.00781]\n",
            "Validating:  62% 10/16 [00:01<00:00,  7.78it/s]\u001b[A\n",
            "Epoch 0:  96% 91/95 [00:33<00:01,  2.73it/s, loss=1.01, v_num=1, val_loss=4.46, val_acc=0.00781]\n",
            "Validating:  75% 12/16 [00:01<00:00,  7.93it/s]\u001b[A\n",
            "Epoch 0:  98% 93/95 [00:33<00:00,  2.77it/s, loss=1.01, v_num=1, val_loss=4.46, val_acc=0.00781]\n",
            "Validating:  88% 14/16 [00:02<00:00,  8.00it/s]\u001b[A\n",
            "Epoch 0: 100% 95/95 [00:34<00:00,  2.78it/s, loss=1.01, v_num=1, val_loss=0.981, val_acc=0.508] \n",
            "Epoch 1:  84% 80/95 [00:32<00:06,  2.49it/s, loss=0.845, v_num=1, val_loss=0.981, val_acc=0.508]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:06,  2.22it/s]\u001b[A\n",
            "Epoch 1:  86% 82/95 [00:32<00:05,  2.50it/s, loss=0.845, v_num=1, val_loss=0.981, val_acc=0.508]\n",
            "Validating:  19% 3/16 [00:00<00:02,  5.05it/s]\u001b[A\n",
            "Epoch 1:  88% 84/95 [00:33<00:04,  2.54it/s, loss=0.845, v_num=1, val_loss=0.981, val_acc=0.508]\n",
            "Validating:  31% 5/16 [00:00<00:01,  6.52it/s]\u001b[A\n",
            "Epoch 1:  91% 86/95 [00:33<00:03,  2.59it/s, loss=0.845, v_num=1, val_loss=0.981, val_acc=0.508]\n",
            "Validating:  44% 7/16 [00:01<00:01,  7.21it/s]\u001b[A\n",
            "Epoch 1:  93% 88/95 [00:33<00:02,  2.63it/s, loss=0.845, v_num=1, val_loss=0.981, val_acc=0.508]\n",
            "Validating:  56% 9/16 [00:01<00:00,  7.58it/s]\u001b[A\n",
            "Epoch 1:  95% 90/95 [00:33<00:01,  2.67it/s, loss=0.845, v_num=1, val_loss=0.981, val_acc=0.508]\n",
            "Validating:  69% 11/16 [00:01<00:00,  7.78it/s]\u001b[A\n",
            "Epoch 1:  97% 92/95 [00:34<00:01,  2.70it/s, loss=0.845, v_num=1, val_loss=0.981, val_acc=0.508]\n",
            "Validating:  81% 13/16 [00:01<00:00,  7.91it/s]\u001b[A\n",
            "Epoch 1:  99% 94/95 [00:34<00:00,  2.74it/s, loss=0.845, v_num=1, val_loss=0.981, val_acc=0.508]\n",
            "Epoch 1: 100% 95/95 [00:34<00:00,  2.73it/s, loss=0.845, v_num=1, val_loss=0.814, val_acc=0.517]\n",
            "Epoch 2:  84% 80/95 [00:32<00:06,  2.47it/s, loss=0.738, v_num=1, val_loss=0.814, val_acc=0.517]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:06,  2.33it/s]\u001b[A\n",
            "Epoch 2:  86% 82/95 [00:32<00:05,  2.49it/s, loss=0.738, v_num=1, val_loss=0.814, val_acc=0.517]\n",
            "Validating:  19% 3/16 [00:00<00:02,  5.15it/s]\u001b[A\n",
            "Epoch 2:  88% 84/95 [00:33<00:04,  2.53it/s, loss=0.738, v_num=1, val_loss=0.814, val_acc=0.517]\n",
            "Validating:  31% 5/16 [00:00<00:01,  6.58it/s]\u001b[A\n",
            "Epoch 2:  91% 86/95 [00:33<00:03,  2.57it/s, loss=0.738, v_num=1, val_loss=0.814, val_acc=0.517]\n",
            "Validating:  44% 7/16 [00:01<00:01,  7.30it/s]\u001b[A\n",
            "Epoch 2:  93% 88/95 [00:33<00:02,  2.61it/s, loss=0.738, v_num=1, val_loss=0.814, val_acc=0.517]\n",
            "Validating:  56% 9/16 [00:01<00:00,  7.65it/s]\u001b[A\n",
            "Epoch 2:  95% 90/95 [00:33<00:01,  2.65it/s, loss=0.738, v_num=1, val_loss=0.814, val_acc=0.517]\n",
            "Validating:  69% 11/16 [00:01<00:00,  7.84it/s]\u001b[A\n",
            "Epoch 2:  97% 92/95 [00:34<00:01,  2.69it/s, loss=0.738, v_num=1, val_loss=0.814, val_acc=0.517]\n",
            "Validating:  81% 13/16 [00:01<00:00,  7.94it/s]\u001b[A\n",
            "Epoch 2:  99% 94/95 [00:34<00:00,  2.73it/s, loss=0.738, v_num=1, val_loss=0.814, val_acc=0.517]\n",
            "Epoch 2: 100% 95/95 [00:34<00:00,  2.72it/s, loss=0.738, v_num=1, val_loss=0.739, val_acc=0.543]\n",
            "Epoch 3:  84% 80/95 [00:32<00:06,  2.49it/s, loss=0.717, v_num=1, val_loss=0.739, val_acc=0.543]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:07,  2.02it/s]\u001b[A\n",
            "Epoch 3:  86% 82/95 [00:32<00:05,  2.50it/s, loss=0.717, v_num=1, val_loss=0.739, val_acc=0.543]\n",
            "Validating:  19% 3/16 [00:00<00:02,  4.80it/s]\u001b[A\n",
            "Epoch 3:  88% 84/95 [00:33<00:04,  2.54it/s, loss=0.717, v_num=1, val_loss=0.739, val_acc=0.543]\n",
            "Validating:  31% 5/16 [00:01<00:01,  6.31it/s]\u001b[A\n",
            "Epoch 3:  91% 86/95 [00:33<00:03,  2.58it/s, loss=0.717, v_num=1, val_loss=0.739, val_acc=0.543]\n",
            "Validating:  44% 7/16 [00:01<00:01,  7.15it/s]\u001b[A\n",
            "Epoch 3:  93% 88/95 [00:33<00:02,  2.62it/s, loss=0.717, v_num=1, val_loss=0.739, val_acc=0.543]\n",
            "Validating:  56% 9/16 [00:01<00:00,  7.50it/s]\u001b[A\n",
            "Epoch 3:  95% 90/95 [00:33<00:01,  2.66it/s, loss=0.717, v_num=1, val_loss=0.739, val_acc=0.543]\n",
            "Validating:  69% 11/16 [00:01<00:00,  7.76it/s]\u001b[A\n",
            "Epoch 3:  97% 92/95 [00:34<00:01,  2.70it/s, loss=0.717, v_num=1, val_loss=0.739, val_acc=0.543]\n",
            "Validating:  81% 13/16 [00:02<00:00,  7.89it/s]\u001b[A\n",
            "Epoch 3:  99% 94/95 [00:34<00:00,  2.74it/s, loss=0.717, v_num=1, val_loss=0.739, val_acc=0.543]\n",
            "Epoch 3: 100% 95/95 [00:34<00:00,  2.73it/s, loss=0.717, v_num=1, val_loss=0.691, val_acc=0.535]\n",
            "Epoch 4:  84% 80/95 [00:32<00:06,  2.48it/s, loss=0.676, v_num=1, val_loss=0.691, val_acc=0.535]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:06,  2.20it/s]\u001b[A\n",
            "Epoch 4:  86% 82/95 [00:32<00:05,  2.50it/s, loss=0.676, v_num=1, val_loss=0.691, val_acc=0.535]\n",
            "Validating:  19% 3/16 [00:00<00:02,  4.97it/s]\u001b[A\n",
            "Epoch 4:  88% 84/95 [00:33<00:04,  2.54it/s, loss=0.676, v_num=1, val_loss=0.691, val_acc=0.535]\n",
            "Validating:  31% 5/16 [00:00<00:01,  6.47it/s]\u001b[A\n",
            "Epoch 4:  91% 86/95 [00:33<00:03,  2.58it/s, loss=0.676, v_num=1, val_loss=0.691, val_acc=0.535]\n",
            "Validating:  44% 7/16 [00:01<00:01,  7.23it/s]\u001b[A\n",
            "Epoch 4:  93% 88/95 [00:33<00:02,  2.62it/s, loss=0.676, v_num=1, val_loss=0.691, val_acc=0.535]\n",
            "Validating:  56% 9/16 [00:01<00:00,  7.62it/s]\u001b[A\n",
            "Epoch 4:  95% 90/95 [00:33<00:01,  2.66it/s, loss=0.676, v_num=1, val_loss=0.691, val_acc=0.535]\n",
            "Validating:  69% 11/16 [00:01<00:00,  7.83it/s]\u001b[A\n",
            "Epoch 4:  97% 92/95 [00:34<00:01,  2.70it/s, loss=0.676, v_num=1, val_loss=0.691, val_acc=0.535]\n",
            "Validating:  81% 13/16 [00:01<00:00,  7.94it/s]\u001b[A\n",
            "Epoch 4:  99% 94/95 [00:34<00:00,  2.74it/s, loss=0.676, v_num=1, val_loss=0.691, val_acc=0.535]\n",
            "Epoch 4: 100% 95/95 [00:34<00:00,  2.73it/s, loss=0.676, v_num=1, val_loss=0.661, val_acc=0.544]\n",
            "Epoch 5:  84% 80/95 [00:32<00:06,  2.48it/s, loss=0.645, v_num=1, val_loss=0.661, val_acc=0.544]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:06,  2.16it/s]\u001b[A\n",
            "Epoch 5:  86% 82/95 [00:32<00:05,  2.50it/s, loss=0.645, v_num=1, val_loss=0.661, val_acc=0.544]\n",
            "Validating:  19% 3/16 [00:00<00:02,  4.99it/s]\u001b[A\n",
            "Epoch 5:  88% 84/95 [00:33<00:04,  2.54it/s, loss=0.645, v_num=1, val_loss=0.661, val_acc=0.544]\n",
            "Validating:  31% 5/16 [00:00<00:01,  6.49it/s]\u001b[A\n",
            "Epoch 5:  91% 86/95 [00:33<00:03,  2.58it/s, loss=0.645, v_num=1, val_loss=0.661, val_acc=0.544]\n",
            "Validating:  44% 7/16 [00:01<00:01,  7.25it/s]\u001b[A\n",
            "Epoch 5:  93% 88/95 [00:33<00:02,  2.62it/s, loss=0.645, v_num=1, val_loss=0.661, val_acc=0.544]\n",
            "Validating:  56% 9/16 [00:01<00:00,  7.64it/s]\u001b[A\n",
            "Epoch 5:  95% 90/95 [00:33<00:01,  2.66it/s, loss=0.645, v_num=1, val_loss=0.661, val_acc=0.544]\n",
            "Validating:  69% 11/16 [00:01<00:00,  7.84it/s]\u001b[A\n",
            "Epoch 5:  97% 92/95 [00:34<00:01,  2.70it/s, loss=0.645, v_num=1, val_loss=0.661, val_acc=0.544]\n",
            "Validating:  81% 13/16 [00:01<00:00,  7.93it/s]\u001b[A\n",
            "Epoch 5:  99% 94/95 [00:34<00:00,  2.74it/s, loss=0.645, v_num=1, val_loss=0.661, val_acc=0.544]\n",
            "Epoch 5: 100% 95/95 [00:34<00:00,  2.73it/s, loss=0.645, v_num=1, val_loss=0.638, val_acc=0.609]\n",
            "Epoch 6:  84% 80/95 [00:32<00:06,  2.49it/s, loss=0.633, v_num=1, val_loss=0.638, val_acc=0.609]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:06,  2.18it/s]\u001b[A\n",
            "Epoch 6:  86% 82/95 [00:32<00:05,  2.50it/s, loss=0.633, v_num=1, val_loss=0.638, val_acc=0.609]\n",
            "Validating:  19% 3/16 [00:00<00:02,  4.98it/s]\u001b[A\n",
            "Epoch 6:  88% 84/95 [00:33<00:04,  2.54it/s, loss=0.633, v_num=1, val_loss=0.638, val_acc=0.609]\n",
            "Validating:  31% 5/16 [00:00<00:01,  6.47it/s]\u001b[A\n",
            "Epoch 6:  91% 86/95 [00:33<00:03,  2.59it/s, loss=0.633, v_num=1, val_loss=0.638, val_acc=0.609]\n",
            "Validating:  44% 7/16 [00:01<00:01,  7.24it/s]\u001b[A\n",
            "Epoch 6:  93% 88/95 [00:33<00:02,  2.63it/s, loss=0.633, v_num=1, val_loss=0.638, val_acc=0.609]\n",
            "Validating:  56% 9/16 [00:01<00:00,  7.64it/s]\u001b[A\n",
            "Epoch 6:  95% 90/95 [00:33<00:01,  2.67it/s, loss=0.633, v_num=1, val_loss=0.638, val_acc=0.609]\n",
            "Validating:  69% 11/16 [00:01<00:00,  7.84it/s]\u001b[A\n",
            "Epoch 6:  97% 92/95 [00:34<00:01,  2.70it/s, loss=0.633, v_num=1, val_loss=0.638, val_acc=0.609]\n",
            "Validating:  81% 13/16 [00:01<00:00,  7.95it/s]\u001b[A\n",
            "Epoch 6:  99% 94/95 [00:34<00:00,  2.74it/s, loss=0.633, v_num=1, val_loss=0.638, val_acc=0.609]\n",
            "Epoch 6: 100% 95/95 [00:34<00:00,  2.74it/s, loss=0.633, v_num=1, val_loss=0.623, val_acc=0.547]\n",
            "Epoch 7:  84% 80/95 [00:32<00:06,  2.48it/s, loss=0.612, v_num=1, val_loss=0.623, val_acc=0.547]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:06,  2.19it/s]\u001b[A\n",
            "Epoch 7:  86% 82/95 [00:32<00:05,  2.50it/s, loss=0.612, v_num=1, val_loss=0.623, val_acc=0.547]\n",
            "Validating:  19% 3/16 [00:00<00:02,  5.02it/s]\u001b[A\n",
            "Epoch 7:  88% 84/95 [00:33<00:04,  2.54it/s, loss=0.612, v_num=1, val_loss=0.623, val_acc=0.547]\n",
            "Validating:  31% 5/16 [00:00<00:01,  6.50it/s]\u001b[A\n",
            "Epoch 7:  91% 86/95 [00:33<00:03,  2.58it/s, loss=0.612, v_num=1, val_loss=0.623, val_acc=0.547]\n",
            "Validating:  44% 7/16 [00:01<00:01,  7.24it/s]\u001b[A\n",
            "Epoch 7:  93% 88/95 [00:33<00:02,  2.62it/s, loss=0.612, v_num=1, val_loss=0.623, val_acc=0.547]\n",
            "Validating:  56% 9/16 [00:01<00:00,  7.63it/s]\u001b[A\n",
            "Epoch 7:  95% 90/95 [00:33<00:01,  2.66it/s, loss=0.612, v_num=1, val_loss=0.623, val_acc=0.547]\n",
            "Validating:  69% 11/16 [00:01<00:00,  7.82it/s]\u001b[A\n",
            "Epoch 7:  97% 92/95 [00:34<00:01,  2.70it/s, loss=0.612, v_num=1, val_loss=0.623, val_acc=0.547]\n",
            "Validating:  81% 13/16 [00:01<00:00,  7.93it/s]\u001b[A\n",
            "Epoch 7:  99% 94/95 [00:34<00:00,  2.74it/s, loss=0.612, v_num=1, val_loss=0.623, val_acc=0.547]\n",
            "Epoch 7: 100% 95/95 [00:34<00:00,  2.73it/s, loss=0.612, v_num=1, val_loss=0.614, val_acc=0.579]\n",
            "Epoch 8:  84% 80/95 [00:32<00:06,  2.48it/s, loss=0.586, v_num=1, val_loss=0.614, val_acc=0.579]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:06,  2.30it/s]\u001b[A\n",
            "Epoch 8:  86% 82/95 [00:32<00:05,  2.50it/s, loss=0.586, v_num=1, val_loss=0.614, val_acc=0.579]\n",
            "Validating:  19% 3/16 [00:00<00:02,  5.13it/s]\u001b[A\n",
            "Epoch 8:  88% 84/95 [00:33<00:04,  2.54it/s, loss=0.586, v_num=1, val_loss=0.614, val_acc=0.579]\n",
            "Validating:  31% 5/16 [00:00<00:01,  6.59it/s]\u001b[A\n",
            "Epoch 8:  91% 86/95 [00:33<00:03,  2.58it/s, loss=0.586, v_num=1, val_loss=0.614, val_acc=0.579]\n",
            "Validating:  44% 7/16 [00:01<00:01,  7.30it/s]\u001b[A\n",
            "Epoch 8:  93% 88/95 [00:33<00:02,  2.62it/s, loss=0.586, v_num=1, val_loss=0.614, val_acc=0.579]\n",
            "Validating:  56% 9/16 [00:01<00:00,  7.66it/s]\u001b[A\n",
            "Epoch 8:  95% 90/95 [00:33<00:01,  2.66it/s, loss=0.586, v_num=1, val_loss=0.614, val_acc=0.579]\n",
            "Validating:  69% 11/16 [00:01<00:00,  7.83it/s]\u001b[A\n",
            "Epoch 8:  97% 92/95 [00:34<00:01,  2.70it/s, loss=0.586, v_num=1, val_loss=0.614, val_acc=0.579]\n",
            "Validating:  81% 13/16 [00:01<00:00,  7.93it/s]\u001b[A\n",
            "Epoch 8:  99% 94/95 [00:34<00:00,  2.74it/s, loss=0.586, v_num=1, val_loss=0.614, val_acc=0.579]\n",
            "Epoch 8: 100% 95/95 [00:34<00:00,  2.73it/s, loss=0.586, v_num=1, val_loss=0.601, val_acc=0.58] \n",
            "Epoch 9:  84% 80/95 [00:32<00:06,  2.48it/s, loss=0.566, v_num=1, val_loss=0.601, val_acc=0.58]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:06,  2.18it/s]\u001b[A\n",
            "Epoch 9:  86% 82/95 [00:32<00:05,  2.50it/s, loss=0.566, v_num=1, val_loss=0.601, val_acc=0.58]\n",
            "Validating:  19% 3/16 [00:00<00:02,  5.01it/s]\u001b[A\n",
            "Epoch 9:  88% 84/95 [00:33<00:04,  2.54it/s, loss=0.566, v_num=1, val_loss=0.601, val_acc=0.58]\n",
            "Validating:  31% 5/16 [00:00<00:01,  6.49it/s]\u001b[A\n",
            "Epoch 9:  91% 86/95 [00:33<00:03,  2.58it/s, loss=0.566, v_num=1, val_loss=0.601, val_acc=0.58]\n",
            "Validating:  44% 7/16 [00:01<00:01,  7.25it/s]\u001b[A\n",
            "Epoch 9:  93% 88/95 [00:33<00:02,  2.62it/s, loss=0.566, v_num=1, val_loss=0.601, val_acc=0.58]\n",
            "Validating:  56% 9/16 [00:01<00:00,  7.62it/s]\u001b[A\n",
            "Epoch 9:  95% 90/95 [00:33<00:01,  2.66it/s, loss=0.566, v_num=1, val_loss=0.601, val_acc=0.58]\n",
            "Validating:  69% 11/16 [00:01<00:00,  7.82it/s]\u001b[A\n",
            "Epoch 9:  97% 92/95 [00:34<00:01,  2.70it/s, loss=0.566, v_num=1, val_loss=0.601, val_acc=0.58]\n",
            "Validating:  81% 13/16 [00:01<00:00,  7.91it/s]\u001b[A\n",
            "Epoch 9:  99% 94/95 [00:34<00:00,  2.74it/s, loss=0.566, v_num=1, val_loss=0.601, val_acc=0.58]\n",
            "Epoch 9: 100% 95/95 [00:34<00:00,  2.73it/s, loss=0.566, v_num=1, val_loss=0.598, val_acc=0.536]\n",
            "Epoch 9: 100% 95/95 [00:34<00:00,  2.73it/s, loss=0.566, v_num=1, val_loss=0.598, val_acc=0.536]\n",
            "EMNISTLinesDataset loading data from HDF5...\n",
            "Testing: 100% 16/16 [00:02<00:00,  6.47it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.5211, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5m0rMebjCJ7",
        "outputId": "f286cc37-6d5f-488d-e842-1a97d0c67709"
      },
      "source": [
        "# Variable-length overlap\n",
        "# --min_overlap=0 --max_overlap=0.33, set the input overlapping to make it more challengable\n",
        "!python training/run_experiment.py --max_epochs=10 --gpus=1 --num_workers=4 --data_class=EMNISTLines --min_overlap=0 --max_overlap=0.33 --model_class=LineCNNSimple --window_width=28 --window_stride=20 --limit_output_length"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "EMNISTLinesDataset generating data for train...\n",
            "EMNISTLinesDataset generating data for val...\n",
            "EMNISTLinesDataset generating data for test...\n",
            "EMNISTLinesDataset loading data from HDF5...\n",
            "2021-08-15 20:48:55.660554: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "   | Name                 | Type          | Params\n",
            "--------------------------------------------------------\n",
            "0  | model                | LineCNNSimple | 1.7 M \n",
            "1  | model.cnn            | CNN           | 1.7 M \n",
            "2  | model.cnn.conv1      | ConvBlock     | 640   \n",
            "3  | model.cnn.conv1.conv | Conv2d        | 640   \n",
            "4  | model.cnn.conv1.relu | ReLU          | 0     \n",
            "5  | model.cnn.conv2      | ConvBlock     | 36.9 K\n",
            "6  | model.cnn.conv2.conv | Conv2d        | 36.9 K\n",
            "7  | model.cnn.conv2.relu | ReLU          | 0     \n",
            "8  | model.cnn.dropout    | Dropout       | 0     \n",
            "9  | model.cnn.max_pool   | MaxPool2d     | 0     \n",
            "10 | model.cnn.fc1        | Linear        | 1.6 M \n",
            "11 | model.cnn.fc2        | Linear        | 10.7 K\n",
            "12 | train_acc            | Accuracy      | 0     \n",
            "13 | val_acc              | Accuracy      | 0     \n",
            "14 | test_acc             | Accuracy      | 0     \n",
            "--------------------------------------------------------\n",
            "1.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.7 M     Total params\n",
            "Epoch 0:  83% 79/95 [00:31<00:06,  2.47it/s, loss=1.64, v_num=2, val_loss=4.46, val_acc=0.00684]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  85% 81/95 [00:32<00:05,  2.50it/s, loss=1.64, v_num=2, val_loss=4.46, val_acc=0.00684]\n",
            "Validating:  12% 2/16 [00:00<00:03,  3.96it/s]\u001b[A\n",
            "Epoch 0:  87% 83/95 [00:32<00:04,  2.54it/s, loss=1.64, v_num=2, val_loss=4.46, val_acc=0.00684]\n",
            "Validating:  25% 4/16 [00:00<00:02,  5.99it/s]\u001b[A\n",
            "Epoch 0:  89% 85/95 [00:32<00:03,  2.58it/s, loss=1.64, v_num=2, val_loss=4.46, val_acc=0.00684]\n",
            "Validating:  38% 6/16 [00:01<00:01,  7.01it/s]\u001b[A\n",
            "Epoch 0:  92% 87/95 [00:33<00:03,  2.62it/s, loss=1.64, v_num=2, val_loss=4.46, val_acc=0.00684]\n",
            "Validating:  50% 8/16 [00:01<00:01,  7.49it/s]\u001b[A\n",
            "Epoch 0:  94% 89/95 [00:33<00:02,  2.66it/s, loss=1.64, v_num=2, val_loss=4.46, val_acc=0.00684]\n",
            "Validating:  62% 10/16 [00:01<00:00,  7.79it/s]\u001b[A\n",
            "Epoch 0:  96% 91/95 [00:33<00:01,  2.70it/s, loss=1.64, v_num=2, val_loss=4.46, val_acc=0.00684]\n",
            "Validating:  75% 12/16 [00:01<00:00,  7.93it/s]\u001b[A\n",
            "Epoch 0:  98% 93/95 [00:33<00:00,  2.74it/s, loss=1.64, v_num=2, val_loss=4.46, val_acc=0.00684]\n",
            "Validating:  88% 14/16 [00:02<00:00,  8.00it/s]\u001b[A\n",
            "Epoch 0: 100% 95/95 [00:34<00:00,  2.75it/s, loss=1.64, v_num=2, val_loss=1.62, val_acc=0.509]  \n",
            "Epoch 1:  84% 80/95 [00:32<00:06,  2.47it/s, loss=1.58, v_num=2, val_loss=1.62, val_acc=0.509]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:07,  2.09it/s]\u001b[A\n",
            "Epoch 1:  86% 82/95 [00:33<00:05,  2.48it/s, loss=1.58, v_num=2, val_loss=1.62, val_acc=0.509]\n",
            "Validating:  19% 3/16 [00:00<00:02,  4.91it/s]\u001b[A\n",
            "Epoch 1:  88% 84/95 [00:33<00:04,  2.52it/s, loss=1.58, v_num=2, val_loss=1.62, val_acc=0.509]\n",
            "Validating:  31% 5/16 [00:00<00:01,  6.44it/s]\u001b[A\n",
            "Epoch 1:  91% 86/95 [00:33<00:03,  2.56it/s, loss=1.58, v_num=2, val_loss=1.62, val_acc=0.509]\n",
            "Validating:  44% 7/16 [00:01<00:01,  7.22it/s]\u001b[A\n",
            "Epoch 1:  93% 88/95 [00:33<00:02,  2.60it/s, loss=1.58, v_num=2, val_loss=1.62, val_acc=0.509]\n",
            "Validating:  56% 9/16 [00:01<00:00,  7.59it/s]\u001b[A\n",
            "Epoch 1:  95% 90/95 [00:34<00:01,  2.64it/s, loss=1.58, v_num=2, val_loss=1.62, val_acc=0.509]\n",
            "Validating:  69% 11/16 [00:01<00:00,  7.83it/s]\u001b[A\n",
            "Epoch 1:  97% 92/95 [00:34<00:01,  2.68it/s, loss=1.58, v_num=2, val_loss=1.62, val_acc=0.509]\n",
            "Validating:  81% 13/16 [00:01<00:00,  7.94it/s]\u001b[A\n",
            "Epoch 1:  99% 94/95 [00:34<00:00,  2.72it/s, loss=1.58, v_num=2, val_loss=1.62, val_acc=0.509]\n",
            "Epoch 1: 100% 95/95 [00:34<00:00,  2.71it/s, loss=1.58, v_num=2, val_loss=1.55, val_acc=0.525]\n",
            "Epoch 2:  84% 80/95 [00:32<00:06,  2.49it/s, loss=1.51, v_num=2, val_loss=1.55, val_acc=0.525]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:06,  2.16it/s]\u001b[A\n",
            "Epoch 2:  86% 82/95 [00:32<00:05,  2.50it/s, loss=1.51, v_num=2, val_loss=1.55, val_acc=0.525]\n",
            "Validating:  19% 3/16 [00:00<00:02,  4.99it/s]\u001b[A\n",
            "Epoch 2:  88% 84/95 [00:33<00:04,  2.54it/s, loss=1.51, v_num=2, val_loss=1.55, val_acc=0.525]\n",
            "Validating:  31% 5/16 [00:00<00:01,  6.40it/s]\u001b[A\n",
            "Epoch 2:  91% 86/95 [00:33<00:03,  2.59it/s, loss=1.51, v_num=2, val_loss=1.55, val_acc=0.525]\n",
            "Validating:  44% 7/16 [00:01<00:01,  7.19it/s]\u001b[A\n",
            "Epoch 2:  93% 88/95 [00:33<00:02,  2.63it/s, loss=1.51, v_num=2, val_loss=1.55, val_acc=0.525]\n",
            "Validating:  56% 9/16 [00:01<00:00,  7.59it/s]\u001b[A\n",
            "Epoch 2:  95% 90/95 [00:33<00:01,  2.67it/s, loss=1.51, v_num=2, val_loss=1.55, val_acc=0.525]\n",
            "Validating:  69% 11/16 [00:01<00:00,  7.82it/s]\u001b[A\n",
            "Epoch 2:  97% 92/95 [00:34<00:01,  2.70it/s, loss=1.51, v_num=2, val_loss=1.55, val_acc=0.525]\n",
            "Validating:  81% 13/16 [00:01<00:00,  7.92it/s]\u001b[A\n",
            "Epoch 2:  99% 94/95 [00:34<00:00,  2.74it/s, loss=1.51, v_num=2, val_loss=1.55, val_acc=0.525]\n",
            "Epoch 2: 100% 95/95 [00:34<00:00,  2.74it/s, loss=1.51, v_num=2, val_loss=1.52, val_acc=0.528]\n",
            "Epoch 3:  84% 80/95 [00:32<00:06,  2.49it/s, loss=1.52, v_num=2, val_loss=1.52, val_acc=0.528]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:06,  2.26it/s]\u001b[A\n",
            "Epoch 3:  86% 82/95 [00:32<00:05,  2.51it/s, loss=1.52, v_num=2, val_loss=1.52, val_acc=0.528]\n",
            "Validating:  19% 3/16 [00:00<00:02,  5.10it/s]\u001b[A\n",
            "Epoch 3:  88% 84/95 [00:32<00:04,  2.55it/s, loss=1.52, v_num=2, val_loss=1.52, val_acc=0.528]\n",
            "Validating:  31% 5/16 [00:00<00:01,  6.57it/s]\u001b[A\n",
            "Epoch 3:  91% 86/95 [00:33<00:03,  2.59it/s, loss=1.52, v_num=2, val_loss=1.52, val_acc=0.528]\n",
            "Validating:  44% 7/16 [00:01<00:01,  7.29it/s]\u001b[A\n",
            "Epoch 3:  93% 88/95 [00:33<00:02,  2.63it/s, loss=1.52, v_num=2, val_loss=1.52, val_acc=0.528]\n",
            "Validating:  56% 9/16 [00:01<00:00,  7.64it/s]\u001b[A\n",
            "Epoch 3:  95% 90/95 [00:33<00:01,  2.67it/s, loss=1.52, v_num=2, val_loss=1.52, val_acc=0.528]\n",
            "Validating:  69% 11/16 [00:01<00:00,  7.85it/s]\u001b[A\n",
            "Epoch 3:  97% 92/95 [00:33<00:01,  2.71it/s, loss=1.52, v_num=2, val_loss=1.52, val_acc=0.528]\n",
            "Validating:  81% 13/16 [00:01<00:00,  7.95it/s]\u001b[A\n",
            "Epoch 3:  99% 94/95 [00:34<00:00,  2.75it/s, loss=1.52, v_num=2, val_loss=1.52, val_acc=0.528]\n",
            "Epoch 3: 100% 95/95 [00:34<00:00,  2.74it/s, loss=1.52, v_num=2, val_loss=1.5, val_acc=0.529] \n",
            "Epoch 4:  84% 80/95 [00:32<00:06,  2.48it/s, loss=1.52, v_num=2, val_loss=1.5, val_acc=0.529]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:06,  2.30it/s]\u001b[A\n",
            "Epoch 4:  86% 82/95 [00:32<00:05,  2.50it/s, loss=1.52, v_num=2, val_loss=1.5, val_acc=0.529]\n",
            "Validating:  19% 3/16 [00:00<00:02,  5.14it/s]\u001b[A\n",
            "Epoch 4:  88% 84/95 [00:33<00:04,  2.54it/s, loss=1.52, v_num=2, val_loss=1.5, val_acc=0.529]\n",
            "Validating:  31% 5/16 [00:00<00:01,  6.59it/s]\u001b[A\n",
            "Epoch 4:  91% 86/95 [00:33<00:03,  2.58it/s, loss=1.52, v_num=2, val_loss=1.5, val_acc=0.529]\n",
            "Validating:  44% 7/16 [00:01<00:01,  7.30it/s]\u001b[A\n",
            "Epoch 4:  93% 88/95 [00:33<00:02,  2.63it/s, loss=1.52, v_num=2, val_loss=1.5, val_acc=0.529]\n",
            "Validating:  56% 9/16 [00:01<00:00,  7.66it/s]\u001b[A\n",
            "Epoch 4:  95% 90/95 [00:33<00:01,  2.67it/s, loss=1.52, v_num=2, val_loss=1.5, val_acc=0.529]\n",
            "Validating:  69% 11/16 [00:01<00:00,  7.86it/s]\u001b[A\n",
            "Epoch 4:  97% 92/95 [00:34<00:01,  2.70it/s, loss=1.52, v_num=2, val_loss=1.5, val_acc=0.529]\n",
            "Validating:  81% 13/16 [00:01<00:00,  7.94it/s]\u001b[A\n",
            "Epoch 4:  99% 94/95 [00:34<00:00,  2.74it/s, loss=1.52, v_num=2, val_loss=1.5, val_acc=0.529]\n",
            "Epoch 4: 100% 95/95 [00:34<00:00,  2.73it/s, loss=1.52, v_num=2, val_loss=1.49, val_acc=0.527]\n",
            "Epoch 5:  84% 80/95 [00:32<00:06,  2.49it/s, loss=1.48, v_num=2, val_loss=1.49, val_acc=0.527]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:06,  2.15it/s]\u001b[A\n",
            "Epoch 5:  86% 82/95 [00:32<00:05,  2.50it/s, loss=1.48, v_num=2, val_loss=1.49, val_acc=0.527]\n",
            "Validating:  19% 3/16 [00:00<00:02,  4.98it/s]\u001b[A\n",
            "Epoch 5:  88% 84/95 [00:33<00:04,  2.54it/s, loss=1.48, v_num=2, val_loss=1.49, val_acc=0.527]\n",
            "Validating:  31% 5/16 [00:00<00:01,  6.49it/s]\u001b[A\n",
            "Epoch 5:  91% 86/95 [00:33<00:03,  2.59it/s, loss=1.48, v_num=2, val_loss=1.49, val_acc=0.527]\n",
            "Validating:  44% 7/16 [00:01<00:01,  7.25it/s]\u001b[A\n",
            "Epoch 5:  93% 88/95 [00:33<00:02,  2.63it/s, loss=1.48, v_num=2, val_loss=1.49, val_acc=0.527]\n",
            "Validating:  56% 9/16 [00:01<00:00,  7.63it/s]\u001b[A\n",
            "Epoch 5:  95% 90/95 [00:33<00:01,  2.67it/s, loss=1.48, v_num=2, val_loss=1.49, val_acc=0.527]\n",
            "Validating:  69% 11/16 [00:01<00:00,  7.83it/s]\u001b[A\n",
            "Epoch 5:  97% 92/95 [00:34<00:01,  2.70it/s, loss=1.48, v_num=2, val_loss=1.49, val_acc=0.527]\n",
            "Validating:  81% 13/16 [00:01<00:00,  7.95it/s]\u001b[A\n",
            "Epoch 5:  99% 94/95 [00:34<00:00,  2.74it/s, loss=1.48, v_num=2, val_loss=1.49, val_acc=0.527]\n",
            "Epoch 5: 100% 95/95 [00:34<00:00,  2.74it/s, loss=1.48, v_num=2, val_loss=1.48, val_acc=0.521]\n",
            "Epoch 6:  84% 80/95 [00:32<00:06,  2.49it/s, loss=1.46, v_num=2, val_loss=1.48, val_acc=0.521]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:06,  2.18it/s]\u001b[A\n",
            "Epoch 6:  86% 82/95 [00:32<00:05,  2.50it/s, loss=1.46, v_num=2, val_loss=1.48, val_acc=0.521]\n",
            "Validating:  19% 3/16 [00:00<00:02,  5.01it/s]\u001b[A\n",
            "Epoch 6:  88% 84/95 [00:33<00:04,  2.55it/s, loss=1.46, v_num=2, val_loss=1.48, val_acc=0.521]\n",
            "Validating:  31% 5/16 [00:00<00:01,  6.49it/s]\u001b[A\n",
            "Epoch 6:  91% 86/95 [00:33<00:03,  2.59it/s, loss=1.46, v_num=2, val_loss=1.48, val_acc=0.521]\n",
            "Validating:  44% 7/16 [00:01<00:01,  7.26it/s]\u001b[A\n",
            "Epoch 6:  93% 88/95 [00:33<00:02,  2.63it/s, loss=1.46, v_num=2, val_loss=1.48, val_acc=0.521]\n",
            "Validating:  56% 9/16 [00:01<00:00,  7.65it/s]\u001b[A\n",
            "Epoch 6:  95% 90/95 [00:33<00:01,  2.67it/s, loss=1.46, v_num=2, val_loss=1.48, val_acc=0.521]\n",
            "Validating:  69% 11/16 [00:01<00:00,  7.86it/s]\u001b[A\n",
            "Epoch 6:  97% 92/95 [00:33<00:01,  2.71it/s, loss=1.46, v_num=2, val_loss=1.48, val_acc=0.521]\n",
            "Validating:  81% 13/16 [00:01<00:00,  7.95it/s]\u001b[A\n",
            "Epoch 6:  99% 94/95 [00:34<00:00,  2.74it/s, loss=1.46, v_num=2, val_loss=1.48, val_acc=0.521]\n",
            "Epoch 6: 100% 95/95 [00:34<00:00,  2.74it/s, loss=1.46, v_num=2, val_loss=1.47, val_acc=0.519]\n",
            "Epoch 7:  84% 80/95 [00:32<00:06,  2.48it/s, loss=1.47, v_num=2, val_loss=1.47, val_acc=0.519]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:07,  2.07it/s]\u001b[A\n",
            "Epoch 7:  86% 82/95 [00:32<00:05,  2.50it/s, loss=1.47, v_num=2, val_loss=1.47, val_acc=0.519]\n",
            "Validating:  19% 3/16 [00:00<00:02,  4.88it/s]\u001b[A\n",
            "Epoch 7:  88% 84/95 [00:33<00:04,  2.54it/s, loss=1.47, v_num=2, val_loss=1.47, val_acc=0.519]\n",
            "Validating:  31% 5/16 [00:00<00:01,  6.35it/s]\u001b[A\n",
            "Epoch 7:  91% 86/95 [00:33<00:03,  2.58it/s, loss=1.47, v_num=2, val_loss=1.47, val_acc=0.519]\n",
            "Validating:  44% 7/16 [00:01<00:01,  7.15it/s]\u001b[A\n",
            "Epoch 7:  93% 88/95 [00:33<00:02,  2.62it/s, loss=1.47, v_num=2, val_loss=1.47, val_acc=0.519]\n",
            "Validating:  56% 9/16 [00:01<00:00,  7.59it/s]\u001b[A\n",
            "Epoch 7:  95% 90/95 [00:33<00:01,  2.66it/s, loss=1.47, v_num=2, val_loss=1.47, val_acc=0.519]\n",
            "Validating:  69% 11/16 [00:01<00:00,  7.82it/s]\u001b[A\n",
            "Epoch 7:  97% 92/95 [00:34<00:01,  2.70it/s, loss=1.47, v_num=2, val_loss=1.47, val_acc=0.519]\n",
            "Validating:  81% 13/16 [00:01<00:00,  7.94it/s]\u001b[A\n",
            "Epoch 7:  99% 94/95 [00:34<00:00,  2.74it/s, loss=1.47, v_num=2, val_loss=1.47, val_acc=0.519]\n",
            "Epoch 7: 100% 95/95 [00:34<00:00,  2.73it/s, loss=1.47, v_num=2, val_loss=1.46, val_acc=0.512]\n",
            "Epoch 8:  84% 80/95 [00:32<00:06,  2.48it/s, loss=1.45, v_num=2, val_loss=1.46, val_acc=0.512]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:06,  2.17it/s]\u001b[A\n",
            "Epoch 8:  86% 82/95 [00:32<00:05,  2.50it/s, loss=1.45, v_num=2, val_loss=1.46, val_acc=0.512]\n",
            "Validating:  19% 3/16 [00:00<00:02,  5.00it/s]\u001b[A\n",
            "Epoch 8:  88% 84/95 [00:33<00:04,  2.54it/s, loss=1.45, v_num=2, val_loss=1.46, val_acc=0.512]\n",
            "Validating:  31% 5/16 [00:00<00:01,  6.50it/s]\u001b[A\n",
            "Epoch 8:  91% 86/95 [00:33<00:03,  2.58it/s, loss=1.45, v_num=2, val_loss=1.46, val_acc=0.512]\n",
            "Validating:  44% 7/16 [00:01<00:01,  7.25it/s]\u001b[A\n",
            "Epoch 8:  93% 88/95 [00:33<00:02,  2.62it/s, loss=1.45, v_num=2, val_loss=1.46, val_acc=0.512]\n",
            "Validating:  56% 9/16 [00:01<00:00,  7.65it/s]\u001b[A\n",
            "Epoch 8:  95% 90/95 [00:33<00:01,  2.66it/s, loss=1.45, v_num=2, val_loss=1.46, val_acc=0.512]\n",
            "Validating:  69% 11/16 [00:01<00:00,  7.85it/s]\u001b[A\n",
            "Epoch 8:  97% 92/95 [00:34<00:01,  2.70it/s, loss=1.45, v_num=2, val_loss=1.46, val_acc=0.512]\n",
            "Validating:  81% 13/16 [00:01<00:00,  7.95it/s]\u001b[A\n",
            "Epoch 8:  99% 94/95 [00:34<00:00,  2.74it/s, loss=1.45, v_num=2, val_loss=1.46, val_acc=0.512]\n",
            "Epoch 8: 100% 95/95 [00:34<00:00,  2.73it/s, loss=1.45, v_num=2, val_loss=1.46, val_acc=0.513]\n",
            "Epoch 9:  84% 80/95 [00:32<00:06,  2.49it/s, loss=1.45, v_num=2, val_loss=1.46, val_acc=0.513]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   6% 1/16 [00:00<00:06,  2.32it/s]\u001b[A\n",
            "Epoch 9:  86% 82/95 [00:32<00:05,  2.51it/s, loss=1.45, v_num=2, val_loss=1.46, val_acc=0.513]\n",
            "Validating:  19% 3/16 [00:00<00:02,  5.17it/s]\u001b[A\n",
            "Epoch 9:  88% 84/95 [00:32<00:04,  2.55it/s, loss=1.45, v_num=2, val_loss=1.46, val_acc=0.513]\n",
            "Validating:  31% 5/16 [00:00<00:01,  6.57it/s]\u001b[A\n",
            "Epoch 9:  91% 86/95 [00:33<00:03,  2.59it/s, loss=1.45, v_num=2, val_loss=1.46, val_acc=0.513]\n",
            "Validating:  44% 7/16 [00:01<00:01,  7.27it/s]\u001b[A\n",
            "Epoch 9:  93% 88/95 [00:33<00:02,  2.63it/s, loss=1.45, v_num=2, val_loss=1.46, val_acc=0.513]\n",
            "Validating:  56% 9/16 [00:01<00:00,  7.65it/s]\u001b[A\n",
            "Epoch 9:  95% 90/95 [00:33<00:01,  2.67it/s, loss=1.45, v_num=2, val_loss=1.46, val_acc=0.513]\n",
            "Validating:  69% 11/16 [00:01<00:00,  7.85it/s]\u001b[A\n",
            "Epoch 9:  97% 92/95 [00:33<00:01,  2.71it/s, loss=1.45, v_num=2, val_loss=1.46, val_acc=0.513]\n",
            "Validating:  81% 13/16 [00:01<00:00,  7.94it/s]\u001b[A\n",
            "Epoch 9:  99% 94/95 [00:34<00:00,  2.75it/s, loss=1.45, v_num=2, val_loss=1.46, val_acc=0.513]\n",
            "Epoch 9: 100% 95/95 [00:34<00:00,  2.74it/s, loss=1.45, v_num=2, val_loss=1.45, val_acc=0.509]\n",
            "Epoch 9: 100% 95/95 [00:34<00:00,  2.74it/s, loss=1.45, v_num=2, val_loss=1.45, val_acc=0.509]\n",
            "EMNISTLinesDataset loading data from HDF5...\n",
            "Testing: 100% 16/16 [00:02<00:00,  6.58it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.5000, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFNJbU7zjYLR",
        "outputId": "f7818e98-0535-446e-f1b5-bfaf37aa47d6"
      },
      "source": [
        "# CTC Loss\n",
        "!python training/run_experiment.py --max_epochs=10 --gpus=1 --num_workers=4 --data_class=EMNISTLines --min_overlap=0.25 --max_overlap=0.25 --model_class=LineCNN --window_width=28 --window_stride=20 --loss=ctc"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "EMNISTLinesDataset loading data from HDF5...\n",
            "2021-08-15 21:00:39.147094: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "   | Name               | Type               | Params\n",
            "-----------------------------------------------------------\n",
            "0  | model              | LineCNN            | 1.2 M \n",
            "1  | model.convs        | Sequential         | 895 K \n",
            "2  | model.convs.0      | ConvBlock          | 320   \n",
            "3  | model.convs.0.conv | Conv2d             | 320   \n",
            "4  | model.convs.0.relu | ReLU               | 0     \n",
            "5  | model.convs.1      | ConvBlock          | 9.2 K \n",
            "6  | model.convs.1.conv | Conv2d             | 9.2 K \n",
            "7  | model.convs.1.relu | ReLU               | 0     \n",
            "8  | model.convs.2      | ConvBlock          | 9.2 K \n",
            "9  | model.convs.2.conv | Conv2d             | 9.2 K \n",
            "10 | model.convs.2.relu | ReLU               | 0     \n",
            "11 | model.convs.3      | ConvBlock          | 9.2 K \n",
            "12 | model.convs.3.conv | Conv2d             | 9.2 K \n",
            "13 | model.convs.3.relu | ReLU               | 0     \n",
            "14 | model.convs.4      | ConvBlock          | 18.5 K\n",
            "15 | model.convs.4.conv | Conv2d             | 18.5 K\n",
            "16 | model.convs.4.relu | ReLU               | 0     \n",
            "17 | model.convs.5      | ConvBlock          | 36.9 K\n",
            "18 | model.convs.5.conv | Conv2d             | 36.9 K\n",
            "19 | model.convs.5.relu | ReLU               | 0     \n",
            "20 | model.convs.6      | ConvBlock          | 73.9 K\n",
            "21 | model.convs.6.conv | Conv2d             | 73.9 K\n",
            "22 | model.convs.6.relu | ReLU               | 0     \n",
            "23 | model.convs.7      | ConvBlock          | 147 K \n",
            "24 | model.convs.7.conv | Conv2d             | 147 K \n",
            "25 | model.convs.7.relu | ReLU               | 0     \n",
            "26 | model.convs.8      | ConvBlock          | 590 K \n",
            "27 | model.convs.8.conv | Conv2d             | 590 K \n",
            "28 | model.convs.8.relu | ReLU               | 0     \n",
            "29 | model.fc1          | Linear             | 262 K \n",
            "30 | model.dropout      | Dropout            | 0     \n",
            "31 | model.fc2          | Linear             | 42.6 K\n",
            "32 | train_acc          | Accuracy           | 0     \n",
            "33 | val_acc            | Accuracy           | 0     \n",
            "34 | test_acc           | Accuracy           | 0     \n",
            "35 | loss_fn            | CTCLoss            | 0     \n",
            "36 | val_cer            | CharacterErrorRate | 0     \n",
            "37 | test_cer           | CharacterErrorRate | 0     \n",
            "-----------------------------------------------------------\n",
            "1.2 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.2 M     Total params\n",
            "Validation sanity check: 0it [00:00, ?it/s]Traceback (most recent call last):\n",
            "  File \"training/run_experiment.py\", line 108, in <module>\n",
            "    main()\n",
            "  File \"training/run_experiment.py\", line 101, in main\n",
            "    trainer.fit(lit_model, datamodule=data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 473, in fit\n",
            "    results = self.accelerator_backend.train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/gpu_accelerator.py\", line 66, in train\n",
            "    results = self.train_or_test()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 69, in train_or_test\n",
            "    results = self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 495, in train\n",
            "    self.run_sanity_check(self.get_model())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 693, in run_sanity_check\n",
            "    _, eval_results = self.run_evaluation(test_mode=False, max_batches=self.num_sanity_val_batches)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 609, in run_evaluation\n",
            "    output = self.evaluation_loop.evaluation_step(test_mode, batch, batch_idx, dataloader_idx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 178, in evaluation_step\n",
            "    output = self.trainer.accelerator_backend.validation_step(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/gpu_accelerator.py\", line 84, in validation_step\n",
            "    return self._step(self.trainer.model.validation_step, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/gpu_accelerator.py\", line 76, in _step\n",
            "    output = model_step(*args)\n",
            "  File \"/content/fsdl-text-recognizer-2021-labs/lab3/text_recognizer/lit_models/ctc.py\", line 92, in validation_step\n",
            "    self.val_acc(decoded, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/metrics/metric.py\", line 154, in forward\n",
            "    self.update(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/metrics/metric.py\", line 200, in wrapped_func\n",
            "    return update(*args, **kwargs)\n",
            "  File \"/content/fsdl-text-recognizer-2021-labs/lab3/text_recognizer/lit_models/base.py\", line 24, in update\n",
            "    preds = torch.nn.functional.softmax(preds, dim=-1)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 1512, in softmax\n",
            "    ret = input.softmax(dim)\n",
            "RuntimeError: \"host_softmax\" not implemented for 'Int'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFaCdP7gna8R",
        "outputId": "1ff4f4d3-8694-4704-e672-0d43819674ac"
      },
      "source": [
        "# Add LSTM\n",
        "!python training/run_experiment.py --max_epochs=10 --gpus=1 --num_workers=4 --data_class=EMNISTLines --min_overlap=0 --max_overlap=0.33 --model_class=LineCNNLSTM --window_width=28 --window_stride=18 --loss=ctc"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "EMNISTLinesDataset loading data from HDF5...\n",
            "2021-08-15 21:01:22.238970: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "   | Name                        | Type               | Params\n",
            "--------------------------------------------------------------------\n",
            "0  | model                       | LineCNNLSTM        | 3.7 M \n",
            "1  | model.line_cnn              | LineCNN            | 1.2 M \n",
            "2  | model.line_cnn.convs        | Sequential         | 895 K \n",
            "3  | model.line_cnn.convs.0      | ConvBlock          | 320   \n",
            "4  | model.line_cnn.convs.0.conv | Conv2d             | 320   \n",
            "5  | model.line_cnn.convs.0.relu | ReLU               | 0     \n",
            "6  | model.line_cnn.convs.1      | ConvBlock          | 9.2 K \n",
            "7  | model.line_cnn.convs.1.conv | Conv2d             | 9.2 K \n",
            "8  | model.line_cnn.convs.1.relu | ReLU               | 0     \n",
            "9  | model.line_cnn.convs.2      | ConvBlock          | 9.2 K \n",
            "10 | model.line_cnn.convs.2.conv | Conv2d             | 9.2 K \n",
            "11 | model.line_cnn.convs.2.relu | ReLU               | 0     \n",
            "12 | model.line_cnn.convs.3      | ConvBlock          | 9.2 K \n",
            "13 | model.line_cnn.convs.3.conv | Conv2d             | 9.2 K \n",
            "14 | model.line_cnn.convs.3.relu | ReLU               | 0     \n",
            "15 | model.line_cnn.convs.4      | ConvBlock          | 18.5 K\n",
            "16 | model.line_cnn.convs.4.conv | Conv2d             | 18.5 K\n",
            "17 | model.line_cnn.convs.4.relu | ReLU               | 0     \n",
            "18 | model.line_cnn.convs.5      | ConvBlock          | 36.9 K\n",
            "19 | model.line_cnn.convs.5.conv | Conv2d             | 36.9 K\n",
            "20 | model.line_cnn.convs.5.relu | ReLU               | 0     \n",
            "21 | model.line_cnn.convs.6      | ConvBlock          | 73.9 K\n",
            "22 | model.line_cnn.convs.6.conv | Conv2d             | 73.9 K\n",
            "23 | model.line_cnn.convs.6.relu | ReLU               | 0     \n",
            "24 | model.line_cnn.convs.7      | ConvBlock          | 147 K \n",
            "25 | model.line_cnn.convs.7.conv | Conv2d             | 147 K \n",
            "26 | model.line_cnn.convs.7.relu | ReLU               | 0     \n",
            "27 | model.line_cnn.convs.8      | ConvBlock          | 590 K \n",
            "28 | model.line_cnn.convs.8.conv | Conv2d             | 590 K \n",
            "29 | model.line_cnn.convs.8.relu | ReLU               | 0     \n",
            "30 | model.line_cnn.fc1          | Linear             | 262 K \n",
            "31 | model.line_cnn.dropout      | Dropout            | 0     \n",
            "32 | model.line_cnn.fc2          | Linear             | 42.6 K\n",
            "33 | model.lstm                  | LSTM               | 2.4 M \n",
            "34 | model.fc                    | Linear             | 42.6 K\n",
            "35 | train_acc                   | Accuracy           | 0     \n",
            "36 | val_acc                     | Accuracy           | 0     \n",
            "37 | test_acc                    | Accuracy           | 0     \n",
            "38 | loss_fn                     | CTCLoss            | 0     \n",
            "39 | val_cer                     | CharacterErrorRate | 0     \n",
            "40 | test_cer                    | CharacterErrorRate | 0     \n",
            "--------------------------------------------------------------------\n",
            "3.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.7 M     Total params\n",
            "Validation sanity check: 0it [00:00, ?it/s]Traceback (most recent call last):\n",
            "  File \"training/run_experiment.py\", line 108, in <module>\n",
            "    main()\n",
            "  File \"training/run_experiment.py\", line 101, in main\n",
            "    trainer.fit(lit_model, datamodule=data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 473, in fit\n",
            "    results = self.accelerator_backend.train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/gpu_accelerator.py\", line 66, in train\n",
            "    results = self.train_or_test()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 69, in train_or_test\n",
            "    results = self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 495, in train\n",
            "    self.run_sanity_check(self.get_model())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 693, in run_sanity_check\n",
            "    _, eval_results = self.run_evaluation(test_mode=False, max_batches=self.num_sanity_val_batches)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 609, in run_evaluation\n",
            "    output = self.evaluation_loop.evaluation_step(test_mode, batch, batch_idx, dataloader_idx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 178, in evaluation_step\n",
            "    output = self.trainer.accelerator_backend.validation_step(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/gpu_accelerator.py\", line 84, in validation_step\n",
            "    return self._step(self.trainer.model.validation_step, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/gpu_accelerator.py\", line 76, in _step\n",
            "    output = model_step(*args)\n",
            "  File \"/content/fsdl-text-recognizer-2021-labs/lab3/text_recognizer/lit_models/ctc.py\", line 92, in validation_step\n",
            "    self.val_acc(decoded, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/metrics/metric.py\", line 154, in forward\n",
            "    self.update(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/metrics/metric.py\", line 200, in wrapped_func\n",
            "    return update(*args, **kwargs)\n",
            "  File \"/content/fsdl-text-recognizer-2021-labs/lab3/text_recognizer/lit_models/base.py\", line 24, in update\n",
            "    preds = torch.nn.functional.softmax(preds, dim=-1)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 1512, in softmax\n",
            "    ret = input.softmax(dim)\n",
            "RuntimeError: \"host_softmax\" not implemented for 'Int'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BPhdlzinlof"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}